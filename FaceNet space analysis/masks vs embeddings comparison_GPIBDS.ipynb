{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from visualization_functions.ipynb\n",
      "Importing Jupyter notebook from helper_functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import randomcolor\n",
    "import pathlib\n",
    "import shutil\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy.spatial.distance import cdist\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from visualization_functions import visualize3DData_hull, visualize2DPCA_hull\n",
    "from helper_functions import distConsistancy, calcDist, calculateCentroidsMedoids, queryOriginalSpace, clusterMap, pairwiseCentralityDistances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load cases and the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gpibdfaceEmbeddingsDict.dict', 'rb') as fh:\n",
    "    cases = pickle.load(fh)\n",
    "\n",
    "# add in new cases\n",
    "    \n",
    "with open('newCasesEmbeddings', 'rb') as fh:\n",
    "    \n",
    "    newCases = pickle.load(fh)\n",
    "\n",
    "newCases['PIGN_241510'] = newCases.pop('PIGN_65731')\n",
    "\n",
    "newEmbds = dict(cases)\n",
    "newEmbds.update(newCases)\n",
    "\n",
    "_ = newEmbds.pop('GPAA1_willis') # there was something wrong with this case; misdiagnosed or something\n",
    "\n",
    "case2disease = {c[c.find('_')+1:]:c[:c.find('_')] for c in newEmbds}\n",
    "\n",
    "case2ethnicity = {'241481': 'AS',\n",
    " '241482': 'AS',\n",
    " '241483': 'AS',\n",
    " '241484': 'AS',\n",
    " '241485': 'EU',\n",
    " '241486': 'AS',\n",
    " '241487': 'EU',\n",
    " '241488': 'EU',\n",
    " '241489': 'AS',\n",
    " '241490': 'EU',\n",
    " '241491': 'EU',\n",
    " '241492': 'EU',\n",
    " '241493': 'EU',\n",
    " '241494': 'EU',\n",
    " '241495': 'EU',\n",
    " '241496': 'EU',\n",
    " '241497': 'EU',\n",
    " '241498': 'EU',\n",
    " '241499': 'EU',\n",
    " '241500': 'AS',\n",
    " '241501': 'EU',\n",
    " '241502': 'EU',\n",
    " '241503': 'EU',\n",
    " '241504': 'AS',\n",
    " '241505': 'AS',\n",
    " '241506': 'MEX',\n",
    " '241507': 'ARAB',\n",
    " '241508': 'AS',\n",
    " '241509': 'EU',\n",
    " '241510': 'EU',\n",
    " '241511': 'EU',\n",
    " '241512': 'ARAB',\n",
    " '241513': 'EU',\n",
    " '241514': 'EU',\n",
    " '241515': 'EU',\n",
    " '241516': 'TURK',\n",
    " '241517': 'TURK',\n",
    " '241518': 'TURK',\n",
    " '241519': 'EU+AFR',\n",
    " '241520': 'EU+AFR',\n",
    " '241521': 'NAF',\n",
    " '241523': 'NAF',\n",
    " '241524': 'EU',\n",
    " '241525': 'EU',\n",
    " '241526': 'EU',\n",
    " '241527': 'EU',\n",
    " '241528': 'EU',\n",
    " '241529': 'IND',\n",
    " '242715': 'EU',\n",
    " '242716': 'EU',\n",
    " '242717': 'TURK',\n",
    " '242718': 'EU',\n",
    " '242719': 'TURK',\n",
    " '242720': 'MEX',\n",
    " '242721': 'MEX',\n",
    " '242722': 'NAF',\n",
    " '242723': 'NAF',\n",
    " '242724': 'FIN',\n",
    " '242725': 'EU',\n",
    " '242726': 'EU',\n",
    " '242727': 'EU',\n",
    " '242728': 'EU',\n",
    " '242729': 'EU',\n",
    " '242730': 'EU',\n",
    " '242731': 'EU',\n",
    " '242732': 'EU',\n",
    " '242733': 'EU',\n",
    " '242734': 'EU',\n",
    " '242735': 'EU',\n",
    " '242736': 'EU',\n",
    " '242737': 'EU',\n",
    " '242738': 'EU',\n",
    " '242739': 'EU',\n",
    " '242740': 'EU',\n",
    " '242743': 'EU',\n",
    " '242744': 'EU',\n",
    " '242745': 'EU',\n",
    " '242747': 'EU',\n",
    " '242748': 'EU',\n",
    " '242749': 'EU',\n",
    " '242750': 'EU',\n",
    " '242751': 'EU',\n",
    " '242752': 'EU',\n",
    " '242753': 'EU',\n",
    " '242754': 'EU',\n",
    " '242756': 'NAF',\n",
    " '242757': 'EU',\n",
    " '242758': 'EU',\n",
    " '242759': 'EU',\n",
    " '242760': 'EU',\n",
    " '242761': 'EU',\n",
    " '242762': 'EU',\n",
    " '242763': 'IND',\n",
    " '242764': 'EU',\n",
    " '242765': 'EU',\n",
    " '242766': 'NAF',\n",
    " '242767': 'NAF',\n",
    " '242768': 'NAF',\n",
    " '242769': 'NAF',\n",
    " '242770': 'NAF',\n",
    " '242771': 'NAF',\n",
    " '242772': 'NAF',\n",
    " '242773': 'NAF',\n",
    " '242774': 'NAF',\n",
    " '242775': 'NAF',\n",
    " '242776': 'NAF',\n",
    " '242777': 'NAF',\n",
    " '242778': 'EU',\n",
    " '242779': 'MID_EA',\n",
    " '242780': 'MID_EA',\n",
    " '244875': 'EU',\n",
    " '244884': 'AS',\n",
    " '250288': 'ARAB',\n",
    " '250293': 'EU',\n",
    " '250300': 'AS'}\n",
    "\n",
    "case2ethnicity['blondheim'] = 'EU'\n",
    "case2ethnicity['leszek'] = 'EU'\n",
    "case2ethnicity['linthicum'] = 'EU'\n",
    "\n",
    "# for normalizing the naming for all cases; not important\n",
    "\n",
    "for c,v in list(cases.items()):\n",
    "    \n",
    "    tmpc = c[c.find('_')+1:]\n",
    "    cases[tmpc] = v\n",
    "    del cases[c]\n",
    "    \n",
    "for c,v in list(newEmbds.items()):\n",
    "    \n",
    "    tmpc = c[c.find('_')+1:]\n",
    "    newEmbds[tmpc] = v\n",
    "    del newEmbds[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optional) load normal faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('normalFaces', 'rb') as fh:\n",
    "    \n",
    "    normal = pickle.load(fh)\n",
    "\n",
    "wNormal = dict(newEmbds)\n",
    "wNormal.update(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('referenceEmbeddingsDict.dict', 'rb') as fh:\n",
    "    referenceEmbeddings = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ethnicity and disease membership vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicityMembership = [case2ethnicity[c] if c in case2ethnicity else 'normal' for c in newEmbds]\n",
    "ethnicityMembershipWN = [case2ethnicity[c] if c in case2ethnicity else 'normal' for c in wNormal]\n",
    "\n",
    "diseaseMembership = [case2disease[c] if c in case2disease else 'normal' for c in newEmbds]\n",
    "diseaseMembershipWN = [case2disease[c] if c in case2disease else 'normal' for c in wNormal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load spaces, masks based (for comparison with the original methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNormals = ['space_GPIBD_pairwise', 'space_GPIBD_correction1', 'space_GPIBD_both']\n",
    "wNormals = ['space_GPIBD_pairwise_Normal', 'space_GPIBD_correction1_Normal', 'space_GPIBD_both_Normal']\n",
    "\n",
    "def loadSpace(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as fh:\n",
    "        tmp = pickle.load(fh)\n",
    "    return tmp\n",
    "\n",
    "testDf_pairwise, testDf_split, testDf_both = list(map(loadSpace, noNormals))\n",
    "testDf_pairwiseWN, testDf_splitWN, testDf_bothWN = list(map(loadSpace, wNormals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for the new embeddings-based reference points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeReferencesProperLast(cases, membershipDictionary, references, k, mult = 1, scheme = 2):\n",
    "    \n",
    "    # makes new references the same way they were made for composite masks; 2 + 1 combinations of syndromic and ethnicity masks\n",
    "    \n",
    "    referenceMasksDict = dict()\n",
    "    assignedK = int(k)\n",
    "    \n",
    "    for syn in set([*membershipDictionary.values()]):\n",
    "\n",
    "    # select the cases that are of this syndrome\n",
    "    # if there are less cases than is the assigned k value, take the num of cases as the k  \n",
    "        tmpPool = [c for c in cases if membershipDictionary[c] == syn]\n",
    "        if len(tmpPool) < k:\n",
    "            k = len(tmpPool)\n",
    "        else:\n",
    "            k = assignedK\n",
    "            \n",
    "            \n",
    "    #     as many times as there are cases create a reference mask (or 'mult' as many times)\n",
    "        \n",
    "        \n",
    "        for i, _ in enumerate(tmpPool*mult):\n",
    "            \n",
    "            # if the pool is currently smaller than the k, replenish it\n",
    "            if len(tmpPool) < k:\n",
    "                tmpPool = [c for c in cases if membershipDictionary[c] == syn]\n",
    "                \n",
    "            tmpSample = [t for t in sample(tmpPool, k)]\n",
    "            tmpAverage = np.average([cases[t] for t in tmpSample], axis=0)\n",
    "            \n",
    "            # remove the cases used in the current tmpAverage from the pool in order to give all cases equal participation\n",
    "            for each in tmpSample:\n",
    "                _ = tmpPool.pop(tmpPool.index(each))\n",
    "\n",
    "    #         combine with all ethnicityReferenceMasks\n",
    "            for mask,vec in references.items():\n",
    "                \n",
    "                tmpName = f'{i}_{syn}_{mask}'\n",
    "                # the syndromic tmpAverage is calculated in twice in order to increase the syndromic effect;\n",
    "                # hence the 2 + 1 scheme\n",
    "                syndromicVec = [tmpAverage] * scheme\n",
    "                referenceMasksDict[tmpName] = np.average(syndromicVec + [vec], axis=0)\n",
    "\n",
    "    return referenceMasksDict\n",
    "\n",
    "def makeReferencesProper3_1(cases, membershipDictionary, k, mult = 1):\n",
    "    \n",
    "    #### without ethnicity reference masks\n",
    "    \n",
    "    referenceMasksDict = dict()\n",
    "    assignedK = int(k)\n",
    "    \n",
    "    for syn in set([*membershipDictionary.values()]):\n",
    "    \n",
    "        tmpPool = [c for c in cases if membershipDictionary[c] == syn]\n",
    "        if len(tmpPool) < k:\n",
    "            k = len(tmpPool)\n",
    "        else:\n",
    "            k = assignedK\n",
    "\n",
    "        #     as many times as there are cases create a reference mask (or 'mult' as many times)\n",
    "        \n",
    "        for i, _ in enumerate(tmpPool*mult):\n",
    "\n",
    "            # if the pool is currently smaller than the k, replenish it\n",
    "            if len(tmpPool) < k:\n",
    "                tmpPool = [c for c in cases if membershipDictionary[c] == syn]\n",
    "\n",
    "            tmpSample = [t for t in sample(tmpPool, k)]\n",
    "            tmpAverage = np.average([cases[t] for t in tmpSample], axis=0)\n",
    "\n",
    "            # remove the cases used in the current tmpAverage from the pool in order to give all cases equal participation\n",
    "            for each in tmpSample:\n",
    "                _ = tmpPool.pop(tmpPool.index(each))\n",
    "\n",
    "            tmpName = f'{i}_{syn}'\n",
    "\n",
    "            referenceMasksDict[tmpName] = tmpAverage\n",
    "\n",
    "    return referenceMasksDict\n",
    "\n",
    "def transformDictToMatrix(d):\n",
    "    \n",
    "    d = {k:list(v[0]) for k,v in d.items()}\n",
    "    df_d = pd.DataFrame.from_dict(d, orient = 'index')\n",
    "    d = df_d.values\n",
    "    \n",
    "    return d\n",
    "\n",
    "def pairwiseNP(cases):\n",
    "    \n",
    "    cases = transformDictToMatrix(cases)\n",
    "    \n",
    "    # snippet from: https://stackoverflow.com/questions/46700326/calculate-distances-between-one-point-in-matrix-from-all-other-points\n",
    "    # study that\n",
    "    \n",
    "    res = np.linalg.norm(cases - cases[:,None], axis=-1)\n",
    "    return res\n",
    "\n",
    "def getAllIndices(x):\n",
    "\n",
    "    composites = sorted(list(set([getComposite(n) for n in x.keys()])))\n",
    "    indicesPerSet = list()\n",
    "    \n",
    "    for c in composites:\n",
    "        tmpIndices = [i for i,k in enumerate(x) if c in k]\n",
    "        indicesPerSet.append(tmpIndices)  \n",
    "    \n",
    "    print(len(indicesPerSet))\n",
    "    \n",
    "    return indicesPerSet\n",
    "\n",
    "def getComposite(name):\n",
    "   \n",
    "    return '_'.join(name.split('_')[:3])\n",
    "\n",
    "def getComposite2(name):\n",
    "   \n",
    "    return '_'.join(name.split('_')[3:])\n",
    "\n",
    "def againstReferencesNP_old2(cases, references):\n",
    "    \n",
    "    # transform both to matrices\n",
    "    \n",
    "    X = transformDictToMatrix(cases)\n",
    "    Y = transformDictToMatrix(references)\n",
    "        \n",
    "    # compute all the distances between these; \n",
    "    # the snippet for dists computing from: https://medium.com/dataholiks-distillery/l2-distance-matrix-vectorization-trick-26aa3247ac6c\n",
    "    # study this\n",
    "    \n",
    "    # dists = np.sqrt(-2 * np.dot(X, Y.T) + np.sum(Y**2, axis=1) + np.sum(X**2, axis=1)[:, np.newaxis])\n",
    "    dists = cdist(X,Y)\n",
    "#     print(dists.shape)\n",
    "    \n",
    "    # get the indices of each set of gene composites and compute the minimum over that\n",
    "    \n",
    "    composites = sorted(list(set([getComposite(n) for n in references.keys()])))\n",
    "    indicesPerSet = list()\n",
    "    \n",
    "    for c in composites:\n",
    "#         print(c)\n",
    "        gene = c.split('_')[1]\n",
    "#         print(gene)\n",
    "        tmpIndices = [i for i,k in enumerate(references) if gene in k]\n",
    "        labelIndices = [k for i,k in enumerate(references) if gene in k]\n",
    "        indicesPerSet.append(tmpIndices)\n",
    "#         print(len(labelIndices))\n",
    "#         print(labelIndices)\n",
    "    \n",
    "    finalDists = np.zeros((len(cases),len(indicesPerSet)))\n",
    "    \n",
    "    for i,t in enumerate(indicesPerSet):\n",
    "        \n",
    "        finalDists[:,i] = np.min(dists[:,t], 1)\n",
    "    \n",
    "    return finalDists\n",
    "\n",
    "def againstReferencesNP_old3(cases, references):\n",
    "    \n",
    "    # transform both to matrices\n",
    "    \n",
    "    X = transformDictToMatrix(cases)\n",
    "    Y = transformDictToMatrix(references)\n",
    "        \n",
    "    # compute all the distances between these; \n",
    "    # the snippet for dists computing from: https://medium.com/dataholiks-distillery/l2-distance-matrix-vectorization-trick-26aa3247ac6c\n",
    "    # study this\n",
    "    \n",
    "    # dists = np.sqrt(-2 * np.dot(X, Y.T) + np.sum(Y**2, axis=1) + np.sum(X**2, axis=1)[:, np.newaxis])\n",
    "    dists = cdist(X,Y)\n",
    "#     print(dists.shape)\n",
    "    \n",
    "    # get the indices of each set of composites and compute the minimum over that\n",
    "    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this bellow is simply for the comparison with the original spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the gene-based distance consistency measures for each of these spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces1 = [testDf_pairwise, testDf_split, testDf_both]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gene lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space: space_GPIBD_pairwise, ({'PGAP3': 0.56, 'PIGA': 0.4, 'PIGN': 0.2667, 'PIGV': 0.9583, 'GPAA1': 1.0, 'PIGU': 0.6, 'PIGT': 0.6154}, 0.6286285714285714)\n",
      "space: space_GPIBD_correction1, ({'PGAP3': 0.68, 'PIGA': 0.16, 'PIGN': 0.1333, 'PIGV': 0.7083, 'GPAA1': 0.4, 'PIGU': 0.8, 'PIGT': 0.3846}, 0.46659999999999996)\n",
      "space: space_GPIBD_both, ({'PGAP3': 0.6, 'PIGA': 0.16, 'PIGN': 0.1333, 'PIGV': 0.875, 'GPAA1': 0.8, 'PIGU': 0.6, 'PIGT': 0.6154}, 0.5405285714285714)\n"
     ]
    }
   ],
   "source": [
    "for name, s in zip(noNormals, spaces1):\n",
    "    tmp = PCA().fit_transform(s)\n",
    "    print(f'space: {name}, {distConsistancy(tmp, set(diseaseMembership), diseaseMembership)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ethn lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space: space_GPIBD_pairwise, ({'AS': 0.3636, 'FIN': 1.0, 'EU+AFR': 1.0, 'ARAB': 1.0, 'EU': 0.3881, 'TURK': 0.4, 'MEX': 1.0, 'IND': 1.0, 'MID_EA': 0.5, 'NAF': 0.7059}, 0.73576)\n",
      "space: space_GPIBD_correction1, ({'AS': 0.0909, 'FIN': 1.0, 'EU+AFR': 0.0, 'ARAB': 1.0, 'EU': 0.2239, 'TURK': 0.4, 'MEX': 0.0, 'IND': 1.0, 'MID_EA': 1.0, 'NAF': 0.6471}, 0.6702375)\n",
      "space: space_GPIBD_both, ({'AS': 0.2727, 'FIN': 1.0, 'EU+AFR': 1.0, 'ARAB': 1.0, 'EU': 0.2537, 'TURK': 0.4, 'MEX': 0.0, 'IND': 1.0, 'MID_EA': 0.5, 'NAF': 0.7647}, 0.6879000000000001)\n"
     ]
    }
   ],
   "source": [
    "for name, s in zip(noNormals, spaces1):\n",
    "    tmp = PCA().fit_transform(s)\n",
    "    print(f'space: {name}, {distConsistancy(tmp, set(case2ethnicity.values()), list(case2ethnicity.values()))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check dsc for a simple all v all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6286285714285714\n",
      "0.73576\n"
     ]
    }
   ],
   "source": [
    "X = transformDictToMatrixsformDictToMatrix(newEmbds)\n",
    "Y = transformDictToMatrix(newEmbds)\n",
    "dists_allVAll = cdist(X,Y)\n",
    "tmp = PCA().fit_transform(dists_allVAll)\n",
    "totalGene, avgGene = distConsistancy(tmp, set(diseaseMembership), diseaseMembership)\n",
    "totalEthn, avgEthn = distConsistancy(tmp, set(case2ethnicity.values()), list(case2ethnicity.values()))\n",
    "print(avgGene)\n",
    "print(avgEthn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# systematically calculate the distance consistency for all the ways you can create a space in: \n",
    "\n",
    "## no correction only; minimized over gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc504fdc20484514a405cb015725bc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef03e5bdf594cb996da99009609d745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ef7be3165d4eeca6f490f49985dfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee5d9aa2ad74062bf0034da072e4d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4df5c33e37486b86b7c264556f0117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bestAverageGene = 0\n",
    "bestParamsGene = {'k':0, 'm':0}\n",
    "bestAverageEthn = 1\n",
    "bestParamsEthn = {'k':0, 'm':0}\n",
    "bestDelta = 0\n",
    "bestOverall = [0, 0]\n",
    "bestOverallSpace = ''\n",
    "bestParamsOverall = {'k':0, 'm':0}\n",
    "\n",
    "trackGen_k_minimized = list()\n",
    "trackGen_m_minimized = list()\n",
    "trackGen_dsc_minimized = list()\n",
    "trackEthn_dsc_minimized = list()\n",
    "\n",
    "for k in tqdm_notebook(range(2, 6)):\n",
    "    for m in tqdm_notebook(range(1, 5)):\n",
    "#             print(f'k:{k}, m:{m}')\n",
    "            \n",
    "            references = makeReferencesProper3_1(newEmbds, case2disease, k, m)\n",
    "            space1_noCorrection_minimized = againstReferencesNP_old2(newEmbds, references)\n",
    "            \n",
    "            # minimized = minimized over gene; might be worth looking into minimizing over correction masks again\n",
    "            \n",
    "            spaces = [space1_noCorrection_minimized]\n",
    "            \n",
    "            spaceNames = ['embeddingsBased_noCorrection_minimized']\n",
    "            \n",
    "            for name, space in zip(spaceNames, spaces):\n",
    "                tmp = PCA().fit_transform(space)\n",
    "                totalGene, avgGene = distConsistancy(tmp, set(diseaseMembership), diseaseMembership)\n",
    "                totalEthn, avgEthn = distConsistancy(tmp, set(case2ethnicity.values()), list(case2ethnicity.values()))\n",
    "                \n",
    "                # save the scores in respect to the two parameters and the parameters\n",
    "                trackGen_k_minimized.append(k)\n",
    "                trackGen_m_minimized.append(m)\n",
    "                trackGen_dsc_minimized.append(avgGene)\n",
    "                trackEthn_dsc_minimized.append(avgEthn)\n",
    "                \n",
    "#                 print(f'Gene__space: {name}, {avgGene}')\n",
    "#                 print(f'Ethn__space: {name}, {avgEthn}')\n",
    "                if avgGene > bestAverageGene:\n",
    "                    bestAverageGene = avgGene\n",
    "                    bestParamsGene['k'], bestParamsGene['m'] = k, m\n",
    "                if avgEthn < bestAverageEthn:\n",
    "                    bestAverageEthn = avgEthn\n",
    "                    bestParamsEthn['k'], bestParamsEthn['m'] = k, m\n",
    "                if (avgGene - avgEthn) > bestDelta:\n",
    "                    bestDelta = avgGene - avgEthn\n",
    "                    bestOverall[0], bestOverall[1] = avgGene, avgEthn\n",
    "                    bestParamsOverall['k'], bestParamsOverall['m'] = k, m\n",
    "                    bestOverallSpace = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.9144857142857142\n",
      "bestParamsGene {'k': 2, 'm': 3}\n",
      "bestAverageEthn 0.501511111111111\n",
      "bestParamsEthn {'k': 5, 'm': 3}\n",
      "bestDelta 0.22186964285714295\n",
      "bestOverall [0.8444571428571429, 0.6225875]\n",
      "bestParamsOverall {'k': 3, 'm': 2}\n",
      "bestOverallSpace embeddingsBased_noCorrection_minimized\n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surface plot the dsc in respect to these two parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSurface(kArray, mArray, genDscArray, ethnDscArray, titl):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "    ax = Axes3D(fig)\n",
    "    #gene lvl\n",
    "    x, y, z = np.array(kArray), np.array(mArray), np.array(genDscArray)\n",
    "    ax1 = ax.plot_trisurf(x, y, z, linewidth=0, antialiased=False, cmap='plasma', edgecolor='none', alpha = 0.75,\n",
    "                          vmin=min(z), vmax=max(z))\n",
    "\n",
    "    #ethn lvl\n",
    "    x, y, z = np.array(kArray), np.array(mArray), np.array(ethnDscArray)\n",
    "    ax2 = ax.plot_trisurf(x, y, z, linewidth=0, antialiased=False, cmap='viridis_r', edgecolor='none', alpha = 0.75,\n",
    "                        vmin=min(z), vmax=max(z))\n",
    "\n",
    "    cbar1 = fig.colorbar(ax1, orientation='vertical', shrink=0.8)\n",
    "    cbar1.set_label('Gene', fontsize = 15)\n",
    "\n",
    "    cbar2 = fig.colorbar(ax2, orientation='vertical', shrink=0.8)\n",
    "    cbar2.set_label('Ethnicity', fontsize = 15)\n",
    "\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('m')\n",
    "    ax.set_zlabel('dsc');\n",
    "    ax.set_title(titl, fontsize = 20)\n",
    "\n",
    "    # fig.colorbar(im, orientation='vertical', shrink=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_minimized, trackGen_m_minimized, trackGen_dsc_minimized, trackEthn_dsc_minimized, titl = 'Distance consistency;\\nno correction, minimized over gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# systematically calculate the distance consistency for all the ways you can create a space in:\n",
    "\n",
    "## no correction only; allVAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494e51f7442449b9a8f904ae247342e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a36cc3318e4ae2bc7f890016389224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937df3ab58e9453ba02bd8fe39e9851e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32191d34ba8a42c596df37d239b44bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381592a450c54169b5a79c805f2c75d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bestAverageGene = 0\n",
    "bestParamsGene = {'k':0, 'm':0}\n",
    "bestAverageEthn = 1\n",
    "bestParamsEthn = {'k':0, 'm':0}\n",
    "bestDelta = 0\n",
    "bestOverall = [0, 0]\n",
    "bestOverallSpace = ''\n",
    "bestParamsOverall = {'k':0, 'm':0}\n",
    "\n",
    "# all v all, simple cdist(X,Y)-based distance computation; to show the power in minimizing over gene\n",
    "\n",
    "trackGen_k_allV = list()\n",
    "trackGen_m_allV = list()\n",
    "trackGen_dsc_allV = list()\n",
    "trackEthn_dsc_allV = list()\n",
    "\n",
    "for k in tqdm_notebook(range(2, 6)):\n",
    "    for m in tqdm_notebook(range(1, 5)):\n",
    "#             print(f'k:{k}, m:{m}')\n",
    "            \n",
    "            references = makeReferencesProper3_1(newEmbds, case2disease, k, m)\n",
    "            space1_noCorrection_allVall = againstReferencesNP_old3(newEmbds, references)\n",
    "            \n",
    "            # minimized = minimized over gene; might be worth looking into minimizing over correction masks again\n",
    "            \n",
    "            spaces = [space1_noCorrection_allVall]\n",
    "            \n",
    "            spaceNames = ['embeddingsBased_noCorrection_AllvAll']\n",
    "            \n",
    "            for name, space in zip(spaceNames, spaces):\n",
    "                tmp = PCA().fit_transform(space)\n",
    "                totalGene, avgGene = distConsistancy(tmp, set(diseaseMembership), diseaseMembership)\n",
    "                totalEthn, avgEthn = distConsistancy(tmp, set(case2ethnicity.values()), list(case2ethnicity.values()))\n",
    "                \n",
    "                # save the scores in respect to the two parameters\n",
    "                trackGen_k_allV.append(k)\n",
    "                trackGen_m_allV.append(m)\n",
    "                trackGen_dsc_allV.append(avgGene)\n",
    "                trackEthn_dsc_allV.append(avgEthn)\n",
    "                \n",
    "#                 print(f'Gene__space: {name}, {avgGene}')\n",
    "#                 print(f'Ethn__space: {name}, {avgEthn}')\n",
    "                if avgGene > bestAverageGene:\n",
    "                    bestAverageGene = avgGene\n",
    "                    bestParamsGene['k'], bestParamsGene['m'] = k, m\n",
    "                if avgEthn < bestAverageEthn:\n",
    "                    bestAverageEthn = avgEthn\n",
    "                    bestParamsEthn['k'], bestParamsEthn['m'] = k, m\n",
    "                if (avgGene - avgEthn) > bestDelta:\n",
    "                    bestDelta = avgGene - avgEthn\n",
    "                    bestOverall[0], bestOverall[1] = avgGene, avgEthn\n",
    "                    bestParamsOverall['k'], bestParamsOverall['m'] = k, m\n",
    "                    bestOverallSpace = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.5809714285714287\n",
      "bestParamsGene {'k': 2, 'm': 2}\n",
      "bestAverageEthn 0.5249\n",
      "bestParamsEthn {'k': 5, 'm': 4}\n",
      "bestDelta 0.0015873015873016927\n",
      "bestOverall [0.5464428571428572, 0.5448555555555555]\n",
      "bestParamsOverall {'k': 3, 'm': 2}\n",
      "bestOverallSpace embeddingsBased_noCorrection_AllvAll\n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_allV, trackGen_m_allV, trackGen_dsc_allV, trackEthn_dsc_allV, 'Distance consistency;\\nno correction, all V all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the stability of the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798db283a7d7496db96dd62eb98e250c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "genDsc = list()\n",
    "ethnDsc = list()\n",
    "\n",
    "for _ in tqdm_notebook(range(50)):\n",
    "    references = makeReferencesProperLast(newEmbds, case2disease, referenceEmbeddings, bestParamsOverall['k'],\n",
    "                                          bestParamsOverall['m'], bestParamsOverall['s'])\n",
    "    space2_withCorrection_minimized = againstReferencesNP_old2(newEmbds, references)\n",
    "    tmp = PCA().fit_transform(space2_withCorrection_minimized)\n",
    "    totalGene, avgGene = distConsistancy(tmp, set(diseaseMembership), diseaseMembership)\n",
    "    totalEthn, avgEthn = distConsistancy(tmp, set(case2ethnicity.values()), list(case2ethnicity.values()))\n",
    "    genDsc.append(avgGene)\n",
    "    ethnDsc.append(avgEthn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=50, minmax=(0.7851714285714284, 0.8349285714285715), mean=0.8087505714285713, variance=0.00010318542448979658, skewness=0.24915818869680662, kurtosis=0.018789491527671842)\n",
      "DescribeResult(nobs=50, minmax=(0.53118, 0.6945888888888888), mean=0.6224558444444445, variance=0.0010060994357173091, skewness=-0.2424906716400856, kurtosis=0.7036187804263583)\n",
      "DescribeResult(nobs=50, minmax=(0.1102063492063492, 0.28279142857142847), mean=0.1862947269841269, variance=0.0009939209185291006, skewness=0.2235723120348155, kurtosis=0.9552423449948777)\n"
     ]
    }
   ],
   "source": [
    "print(describe(genDsc))\n",
    "print(describe(ethnDsc))\n",
    "print(describe([i-j for i,j in zip(genDsc, ethnDsc)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with correction; minimized over gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569afb382f7e4b958f043864ad5359c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffe74bc56f9433fb6a668e56d49d94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c63686111d04877957baeda6a64f7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52689daf3554474bb7d98b04837b88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d68f74b10748c68774ec4f41601840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestAverageGene = 0\n",
    "bestParamsGene = {'k':0, 'm':0}\n",
    "bestAverageEthn = 1\n",
    "bestParamsEthn = {'k':0, 'm':0}\n",
    "bestDelta = 0\n",
    "bestOverall = [0, 0]\n",
    "bestOverallSpace = ''\n",
    "bestParamsOverall = {'k':0, 'm':0}\n",
    "\n",
    "trackGen_k_minimized = list()\n",
    "trackGen_m_minimized = list()\n",
    "trackGen_dsc_minimized = list()\n",
    "trackEthn_dsc_minimized = list()\n",
    "\n",
    "##########\n",
    "s = 5 #### Fixed s so we can plot the dsc in respect to k and m\n",
    "##########\n",
    "\n",
    "for k in tqdm_notebook(range(2, 6)):\n",
    "    for m in tqdm_notebook(range(1, 5)):\n",
    "            \n",
    "            references = makeReferencesProperLast(newEmbds, case2disease, referenceEmbeddings, k, m, s)\n",
    "            space2_withCorrection_minimized = againstReferencesNP_old2(newEmbds, references)\n",
    "            \n",
    "            # minimized = minimized over gene; might be worth looking into minimizing over correction masks again\n",
    "            \n",
    "            spaces = [space2_withCorrection_minimized]\n",
    "            \n",
    "            spaceNames = ['embeddingsBased_withCorrection_minimized']\n",
    "            \n",
    "            for name, space in zip(spaceNames, spaces):\n",
    "                tmp = PCA().fit_transform(space)\n",
    "                totalGene, avgGene = distConsistancy(tmp, set(diseaseMembership), diseaseMembership)\n",
    "                totalEthn, avgEthn = distConsistancy(tmp, set(case2ethnicity.values()), list(case2ethnicity.values()))\n",
    "                \n",
    "                # save the scores in respect to the parameters\n",
    "                trackGen_k_minimized.append(k)\n",
    "                trackGen_m_minimized.append(m)\n",
    "                trackGen_dsc_minimized.append(avgGene)\n",
    "                trackEthn_dsc_minimized.append(avgEthn)\n",
    "                \n",
    "#                 print(f'Gene__space: {name}, {avgGene}')\n",
    "#                 print(f'Ethn__space: {name}, {avgEthn}')\n",
    "                if avgGene > bestAverageGene:\n",
    "                    bestAverageGene = avgGene\n",
    "                    bestParamsGene['k'], bestParamsGene['m'] = k, m\n",
    "                if avgEthn < bestAverageEthn:\n",
    "                    bestAverageEthn = avgEthn\n",
    "                    bestParamsEthn['k'], bestParamsEthn['m'] = k, m\n",
    "                if (avgGene - avgEthn) > bestDelta:\n",
    "                    bestDelta = avgGene - avgEthn\n",
    "                    bestOverall[0], bestOverall[1] = avgGene, avgEthn\n",
    "                    bestParamsOverall['k'], bestParamsOverall['m'] = k, m\n",
    "                    bestOverallSpace = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.8387428571428571\n",
      "bestParamsGene {'k': 2, 'm': 4}\n",
      "bestAverageEthn 0.56965\n",
      "bestParamsEthn {'k': 5, 'm': 1}\n",
      "bestDelta 0.24692000000000003\n",
      "bestOverall [0.8328, 0.58588]\n",
      "bestParamsOverall {'k': 2, 'm': 1}\n",
      "bestOverallSpace embeddingsBased_withCorrection_minimized\n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_minimized, trackGen_m_minimized, trackGen_dsc_minimized, trackEthn_dsc_minimized, 'Distance consistency\\nWith correction, minimized, s = 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.8615999999999999\n",
      "bestParamsGene {'k': 2, 'm': 3}\n",
      "bestAverageEthn 0.5315\n",
      "bestParamsEthn {'k': 5, 'm': 1}\n",
      "bestDelta 0.22566142857142846\n",
      "bestOverall [0.8520714285714285, 0.62641]\n",
      "bestParamsOverall {'k': 2, 'm': 2}\n",
      "bestOverallSpace embeddingsBased_withCorrection_minimized\n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_minimized, trackGen_m_minimized, trackGen_dsc_minimized, trackEthn_dsc_minimized, 'Distance consistency\\nWith correction, minimized, s = 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.8916285714285713\n",
      "bestParamsGene {'k': 2, 'm': 2}\n",
      "bestAverageEthn 0.52712\n",
      "bestParamsEthn {'k': 5, 'm': 2}\n",
      "bestDelta 0.2677128571428571\n",
      "bestOverall [0.8806428571428571, 0.61293]\n",
      "bestParamsOverall {'k': 2, 'm': 3}\n",
      "bestOverallSpace embeddingsBased_withCorrection_minimized\n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_minimized, trackGen_m_minimized, trackGen_dsc_minimized, trackEthn_dsc_minimized, 'Distance consistency\\nWith correction, minimized, s = 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.8916285714285713\n",
      "bestParamsGene {'k': 2, 'm': 2}\n",
      "bestAverageEthn 0.5486555555555556\n",
      "bestParamsEthn {'k': 5, 'm': 2}\n",
      "bestDelta 0.22130142857142854\n",
      "bestOverall [0.7739714285714285, 0.55267]\n",
      "bestParamsOverall {'k': 4, 'm': 2}\n",
      "bestOverallSpace embeddingsBased_withCorrection_minimized\n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_minimized, trackGen_m_minimized, trackGen_dsc_minimized, trackEthn_dsc_minimized, 'Distance consistency\\nWith correction, minimized, s = 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with correction; all v all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455c0a7872554626a46174b17dff2eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539e0866eb99410599dc4bc4b4d151e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a27b85196bc4c529898d7216eb6a154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784def66e9364c3ba954210bd2935037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2ab8aaf245452a87b4465887b65f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestAverageGene = 0\n",
    "bestParamsGene = {'k':0, 'm':0}\n",
    "bestAverageEthn = 1\n",
    "bestParamsEthn = {'k':0, 'm':0}\n",
    "bestDelta = 0\n",
    "bestOverall = [0, 0]\n",
    "bestOverallSpace = ''\n",
    "bestParamsOverall = {'k':0, 'm':0}\n",
    "\n",
    "# all v all, simple cdist(X,Y)-based distance computation; to show the power in minimizing over gene\n",
    "\n",
    "trackGen_k_allV = list()\n",
    "trackGen_m_allV = list()\n",
    "trackGen_dsc_allV = list()\n",
    "trackEthn_dsc_allV = list()\n",
    "\n",
    "##########\n",
    "s = 4  ### Fixed so we can plot the dsc in respect to k and m\n",
    "##########\n",
    "\n",
    "for k in tqdm_notebook(range(2, 6)):\n",
    "    for m in tqdm_notebook(range(1, 5)):\n",
    "#             print(f'k:{k}, m:{m}, s:{s}')\n",
    "            \n",
    "            references = makeReferencesProperLast(newEmbds, case2disease, referenceEmbeddings, k, m, s)\n",
    "            space2_withCorrection_allVall = againstReferencesNP_old3(newEmbds, references)\n",
    "            \n",
    "            # minimized = minimized over gene; might be worth looking into minimizing over correction masks again\n",
    "            \n",
    "            spaces = [space2_withCorrection_allVall]\n",
    "            \n",
    "            spaceNames = ['embeddingsBased_withCorrection_AllvAll']\n",
    "            \n",
    "            for name, space in zip(spaceNames, spaces):\n",
    "                tmp = PCA().fit_transform(space)\n",
    "                totalGene, avgGene = distConsistancy(tmp, set(diseaseMembership), diseaseMembership)\n",
    "                totalEthn, avgEthn = distConsistancy(tmp, set(case2ethnicity.values()), list(case2ethnicity.values()))\n",
    "                \n",
    "                # save the scores in respect to the parameters\n",
    "                # save the scores in respect to the two parameters\n",
    "                trackGen_k_allV.append(k)\n",
    "                trackGen_m_allV.append(m)\n",
    "                trackGen_dsc_allV.append(avgGene)\n",
    "                trackEthn_dsc_allV.append(avgEthn)\n",
    "                \n",
    "#                 print(f'Gene__space: {name}, {avgGene}')\n",
    "#                 print(f'Ethn__space: {name}, {avgEthn}')\n",
    "                if avgGene > bestAverageGene:\n",
    "                    bestAverageGene = avgGene\n",
    "                    bestParamsGene['k'], bestParamsGene['m'] = k, m\n",
    "                if avgEthn < bestAverageEthn:\n",
    "                    bestAverageEthn = avgEthn\n",
    "                    bestParamsEthn['k'], bestParamsEthn['m'] = k, m\n",
    "                if (avgGene - avgEthn) > bestDelta:\n",
    "                    bestDelta = avgGene - avgEthn\n",
    "                    bestOverall[0], bestOverall[1] = avgGene, avgEthn\n",
    "                    bestParamsOverall['k'], bestParamsOverall['m'] = k, m\n",
    "                    bestOverallSpace = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.4945428571428572\n",
      "bestParamsGene {'k': 2, 'm': 3}\n",
      "bestAverageEthn 0.5768899999999999\n",
      "bestParamsEthn {'k': 5, 'm': 1}\n",
      "bestDelta 0\n",
      "bestOverall [0, 0]\n",
      "bestParamsOverall {'k': 0, 'm': 0}\n",
      "bestOverallSpace \n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_allV, trackGen_m_allV, trackGen_dsc_allV, trackEthn_dsc_allV, 'Distance consistency;\\nno correction, all V all, s = 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAverageGene 0.5367285714285714\n",
      "bestParamsGene {'k': 2, 'm': 3}\n",
      "bestAverageEthn 0.51653\n",
      "bestParamsEthn {'k': 5, 'm': 4}\n",
      "bestDelta 0\n",
      "bestOverall [0, 0]\n",
      "bestParamsOverall {'k': 0, 'm': 0}\n",
      "bestOverallSpace \n"
     ]
    }
   ],
   "source": [
    "dscVals = ['bestAverageGene',\n",
    "'bestParamsGene',\n",
    "'bestAverageEthn',\n",
    "'bestParamsEthn',\n",
    "'bestDelta',\n",
    "'bestOverall',\n",
    "'bestParamsOverall',\n",
    "'bestOverallSpace']\n",
    "for v in dscVals:\n",
    "    print(f'{v} {eval(v)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurface(trackGen_k_allV, trackGen_m_allV, trackGen_dsc_allV, trackEthn_dsc_allV, 'Distance consistency;\\nno correction, all V all, s = 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# leave one out; different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortUnique(n):\n",
    "    n = np.array(n)\n",
    "    _, idx = np.unique(n, return_index=True)\n",
    "    n = n[np.sort(idx)]\n",
    "    return list(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeClassifiers():\n",
    "    \n",
    "    clsNames = ['linearSvm1', 'linear2', 'linear3', 'kernelSvm3', 'kernelSvm4']\n",
    "    cls = [\n",
    "    SVC(kernel=\"linear\", C= 1, cache_size=300),\n",
    "    SVC(kernel='linear', C = 10, cache_size=300),\n",
    "    SVC(kernel='linear', C = 15, cache_size=300),\n",
    "    SVC(kernel='rbf', C = 10, gamma=0.001, cache_size=300),\n",
    "    SVC(kernel='rbf', C = 1000, gamma=0.001, cache_size=300)]\n",
    "    \n",
    "    return clsNames, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51097e880da34542ad1d6947f0bda4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "linearSvm1 0.5803571428571429\n",
      "linear2 0.5625\n",
      "linear3 0.5625\n",
      "kernelSvm3 0.16964285714285715\n",
      "kernelSvm4 0.5714285714285714\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e3837332dd49deb77d08af2254a10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2\n",
      "linearSvm1 0.5892857142857143\n",
      "linear2 0.5357142857142857\n",
      "linear3 0.5357142857142857\n",
      "kernelSvm3 0.4642857142857143\n",
      "kernelSvm4 0.5714285714285714\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a514c055c644f62b37c0e2317dee031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-766d7c6e8265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mreferences_NoCorrection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeReferencesProper3_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainCases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase2disease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mdistsTrain1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magainstReferencesNP_old3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainCases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferences_NoCorrection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mdistsTest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magainstReferencesNP_old3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestCases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferences_NoCorrection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-4ac75483c19a>\u001b[0m in \u001b[0;36magainstReferencesNP_old3\u001b[1;34m(cases, references)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;31m# transform both to matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformDictToMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformDictToMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-4ac75483c19a>\u001b[0m in \u001b[0;36mtransformDictToMatrix\u001b[1;34m(d)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mdf_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(cls, data, orient, dtype)\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'only recognize index or columns for orient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                     mgr = _arrays_to_mgr(arrays, columns, index, columns,\n\u001b[1;32m--> 327\u001b[1;33m                                          dtype=dtype)\n\u001b[0m\u001b[0;32m    328\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   5504\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5506\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   4307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4309\u001b[1;33m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4310\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4311\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mform_blocks\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   4371\u001b[0m     \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4372\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4373\u001b[1;33m         \u001b[0mfloat_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multi_blockify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4374\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_multi_blockify\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   4448\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup_block\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4450\u001b[1;33m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4452\u001b[0m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   4493\u001b[0m     \u001b[0mstacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4494\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4495\u001b[1;33m         \u001b[0mstacked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4497\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "for k in range(4, 5):\n",
    "    for m in range(1, 5):\n",
    "        \n",
    "        kf = KFold(n_splits=len(newEmbds))\n",
    "        kf.get_n_splits(newEmbds)\n",
    "\n",
    "        totalScore = list()\n",
    "        bar = tqdm_notebook(kf.split(newEmbds), total = len(newEmbds))\n",
    "\n",
    "        clsNames, _ = makeClassifiers()\n",
    "        scores1 = {k:list() for k in clsNames}\n",
    "#         scores = list()\n",
    "\n",
    "        for train_index, test_index in bar:\n",
    "\n",
    "            trainCases = {k:v for i, (k,v) in enumerate(newEmbds.items()) if i not in test_index}\n",
    "            trainLabels = list({k:v for k,v in case2disease.items() if k in trainCases}.values())\n",
    "\n",
    "            testKey = list(newEmbds.keys())[test_index[0]]\n",
    "            testCases = {testKey: newEmbds[testKey]}\n",
    "            testLabels = [(case2disease[testKey])]\n",
    "\n",
    "            ## parameters selected because of the best space above; this is best overall\n",
    "#             references_wCorrection = makeReferencesProperLast(trainCases, case2disease, referenceEmbeddings, k, m, 4)\n",
    "#             distsTrain1 = againstReferencesNP_old3(trainCases, references_wCorrection)\n",
    "#             distsTest1 = againstReferencesNP_old3(testCases, references_wCorrection)\n",
    "        \n",
    "            references_NoCorrection = makeReferencesProper3_1(trainCases, case2disease, k, m)\n",
    "            distsTrain1 = againstReferencesNP_old3(trainCases, references_NoCorrection)      \n",
    "            distsTest1 = againstReferencesNP_old3(testCases, references_NoCorrection)\n",
    "\n",
    "#             classfiers:\n",
    "            clsNames, cls = makeClassifiers()\n",
    "            \n",
    "            for name, cl in zip(clsNames, cls):\n",
    "                cl.fit(distsTrain1, trainLabels)\n",
    "                scores1[name].append(cl.score(distsTest1, testLabels))\n",
    "            \n",
    "        print(k, m)\n",
    "        for key, val in scores1.items():\n",
    "            print(key, np.mean(val))\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
